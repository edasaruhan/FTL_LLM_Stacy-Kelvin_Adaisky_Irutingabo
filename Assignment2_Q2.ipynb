{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Structured Approach for NLP Project: Text Embeddings**\n",
    "\n",
    "#### **Explore and Compare Text Embeddings**\n",
    "\n",
    "1. **Word2Vec:**\n",
    "   - **Overview:** Shallow neural network model by Google for word vector representations.\n",
    "   - **Key Features:** Captures semantic meaning; uses CBOW and Skip-Gram models.\n",
    "\n",
    "2. **GloVe:**\n",
    "   - **Overview:** Unsupervised algorithm by Stanford for word embeddings based on global word co-occurrence.\n",
    "   - **Key Features:** Combines Word2Vec and matrix factorization advantages.\n",
    "\n",
    "3. **BERT:**\n",
    "   - **Overview:** Transformer-based model by Google that generates context-aware embeddings.\n",
    "   - **Key Features:** Pretrained on large datasets (e.g., Wikipedia) and fine-tuned for specific tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas numpy scikit-learn gensim transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Budget to set scene for election\\n \\n Gordon B...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Army chiefs in regiments decision\\n \\n Militar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Howard denies split over ID cards\\n \\n Michael...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Observers to monitor UK election\\n \\n Minister...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kilroy names election seat target\\n \\n Ex-chat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label\n",
       "0  Budget to set scene for election\\n \\n Gordon B...      0\n",
       "1  Army chiefs in regiments decision\\n \\n Militar...      0\n",
       "2  Howard denies split over ID cards\\n \\n Michael...      0\n",
       "3  Observers to monitor UK election\\n \\n Minister...      0\n",
       "4  Kilroy names election seat target\\n \\n Ex-chat...      0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"df_file.csv\")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Text', 'Label'], dtype='object')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove special characters\n",
    "    text = ''.join(e for e in text if e.isalnum() or e.isspace())\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing\n",
    "df['cleaned_text'] = df['Text'].apply(preprocess_text)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Budget to set scene for election\\n \\n Gordon B...</td>\n",
       "      <td>0</td>\n",
       "      <td>budget to set scene for election\\n \\n gordon b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Army chiefs in regiments decision\\n \\n Militar...</td>\n",
       "      <td>0</td>\n",
       "      <td>army chiefs in regiments decision\\n \\n militar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Howard denies split over ID cards\\n \\n Michael...</td>\n",
       "      <td>0</td>\n",
       "      <td>howard denies split over id cards\\n \\n michael...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Observers to monitor UK election\\n \\n Minister...</td>\n",
       "      <td>0</td>\n",
       "      <td>observers to monitor uk election\\n \\n minister...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kilroy names election seat target\\n \\n Ex-chat...</td>\n",
       "      <td>0</td>\n",
       "      <td>kilroy names election seat target\\n \\n exchat ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Label  \\\n",
       "0  Budget to set scene for election\\n \\n Gordon B...      0   \n",
       "1  Army chiefs in regiments decision\\n \\n Militar...      0   \n",
       "2  Howard denies split over ID cards\\n \\n Michael...      0   \n",
       "3  Observers to monitor UK election\\n \\n Minister...      0   \n",
       "4  Kilroy names election seat target\\n \\n Ex-chat...      0   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  budget to set scene for election\\n \\n gordon b...  \n",
       "1  army chiefs in regiments decision\\n \\n militar...  \n",
       "2  howard denies split over id cards\\n \\n michael...  \n",
       "3  observers to monitor uk election\\n \\n minister...  \n",
       "4  kilroy names election seat target\\n \\n exchat ...  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X = df['cleaned_text']\n",
    "y = df['Label'] \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec\n",
    "# Tokenize the training data\n",
    "train_tokens = [tweet.split() for tweet in X_train]\n",
    "word2vec_model = Word2Vec(sentences=train_tokens, vector_size=100, window=5, min_count=1, workers=4)\n",
    "def get_word2vec_embeddings(tweets):\n",
    "    embeddings = []\n",
    "    for tweet in tweets:\n",
    "        # Get the vectors for words in the tweet\n",
    "        word_vectors = [word2vec_model.wv[word] for word in tweet.split() if word in word2vec_model.wv]\n",
    "        \n",
    "        # Check if word_vectors is not empty\n",
    "        if word_vectors:\n",
    "            vec = np.mean(word_vectors, axis=0)\n",
    "        else:\n",
    "            # If no words are found, create a zero vector\n",
    "            vec = np.zeros(word2vec_model.vector_size)\n",
    "        \n",
    "        embeddings.append(vec)\n",
    "    return np.array(embeddings)\n",
    "\n",
    "X_train_w2v = get_word2vec_embeddings(X_train)\n",
    "X_test_w2v = get_word2vec_embeddings(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GloVe\n",
    "glove_file = 'glove.6B.100d.txt' \n",
    "glove_vectors = {}\n",
    "with open(glove_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vectors = np.array(values[1:], dtype='float32')\n",
    "        glove_vectors[word] = vectors\n",
    "\n",
    "def get_glove_embeddings(tweets):\n",
    "    embeddings = []\n",
    "    for tweet in tweets:\n",
    "        # Get the vectors for words in the tweet\n",
    "        glove_vectors_found = [glove_vectors[word] for word in tweet.split() if word in glove_vectors]\n",
    "        \n",
    "        # Check if glove_vectors_found is not empty\n",
    "        if glove_vectors_found:\n",
    "            vec = np.mean(glove_vectors_found, axis=0)\n",
    "        else:\n",
    "            # If no words are found, create a zero vector\n",
    "            vec = np.zeros(100) \n",
    "        \n",
    "        embeddings.append(vec)\n",
    "    return np.array(embeddings)\n",
    "\n",
    "\n",
    "X_train_glove = get_glove_embeddings(X_train)\n",
    "X_test_glove = get_glove_embeddings(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kelvi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "# BERT\n",
    "# Load BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def get_bert_embeddings(tweets):\n",
    "    embeddings = []\n",
    "    for tweet in tweets:\n",
    "        inputs = tokenizer(tweet, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "        outputs = bert_model(**inputs)\n",
    "        vec = outputs.last_hidden_state.mean(dim=1).detach().numpy()  \n",
    "        embeddings.append(vec.flatten())\n",
    "    return np.array(embeddings)\n",
    "\n",
    "X_train_bert = get_bert_embeddings(X_train.tolist())\n",
    "X_test_bert = get_bert_embeddings(X_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training and Evaluation\n",
    "\n",
    "def evaluate_model(X_train, X_test, y_train, y_test):\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec Embeddings:\n",
      "Accuracy: 0.8247, Precision: 0.8253, Recall: 0.8247, F1-score: 0.8237\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the models\n",
    "print(\"Word2Vec Embeddings:\")\n",
    "results_w2v = evaluate_model(X_train_w2v, X_test_w2v, y_train, y_test)\n",
    "print(f\"Accuracy: {results_w2v[0]:.4f}, Precision: {results_w2v[1]:.4f}, Recall: {results_w2v[2]:.4f}, F1-score: {results_w2v[3]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GloVe Embeddings:\n",
      "Accuracy: 0.9483, Precision: 0.9491, Recall: 0.9483, F1-score: 0.9481\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGloVe Embeddings:\")\n",
    "results_glove = evaluate_model(X_train_glove, X_test_glove, y_train, y_test)\n",
    "print(f\"Accuracy: {results_glove[0]:.4f}, Precision: {results_glove[1]:.4f}, Recall: {results_glove[2]:.4f}, F1-score: {results_glove[3]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BERT Embeddings:\n",
      "Accuracy: 0.9843, Precision: 0.9846, Recall: 0.9843, F1-score: 0.9842\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBERT Embeddings:\")\n",
    "results_bert = evaluate_model(X_train_bert, X_test_bert, y_train, y_test)\n",
    "print(f\"Accuracy: {results_bert[0]:.4f}, Precision: {results_bert[1]:.4f}, Recall: {results_bert[2]:.4f}, F1-score: {results_bert[3]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Comparison of Embedding Types for Text Classification**\n",
    "\n",
    "| **Embedding Type** | **Accuracy** | **Precision** | **Recall** | **F1-score** |\n",
    "|--------------------|--------------|---------------|------------|--------------|\n",
    "| **BERT**           | 0.9843       | 0.9846        | 0.9843     | 0.9842       |\n",
    "| **GloVe**          | 0.9483       | 0.9491        | 0.9483     | 0.9481       |\n",
    "| **Word2Vec**       | 0.8247       | 0.8253        | 0.8247     | 0.8237       |\n",
    "\n",
    "### **Findings and Insights**\n",
    "\n",
    "- **BERT:** Best performer with highest accuracy (0.9843) and balanced metrics due to its ability to understand context. However, it is computationally expensive.\n",
    "- **GloVe:** Moderate performance (accuracy: 0.9483). Efficient and good for general NLP tasks but lacks context sensitivity.\n",
    "- **Word2Vec:** Lowest performance (accuracy: 0.8247), suitable for simpler tasks and environments with limited resources due to its lower computational cost.\n",
    "\n",
    "### **Conclusion:**\n",
    "- **Use BERT** for tasks needing deep contextual understanding.\n",
    "- **Choose GloVe** for a balance between efficiency and performance.\n",
    "- **Apply Word2Vec** for simple tasks requiring speed over accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
